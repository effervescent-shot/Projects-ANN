{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Miniproject 1: Image Classification\n",
    "\n",
    "## Introduction\n",
    "\n",
    "### Important dates:\n",
    "\n",
    "- Project release: Friday, 15th March 2019\n",
    "- **Submission deadline**: Monday, 29th April 2019, 11:59 pm\n",
    "\n",
    "### Description\n",
    "\n",
    "One of the deepest traditions in learning about deep learning is to first [tackle the exciting problem of MNIST classification](http://yann.lecun.com/exdb/mnist/). [The MNIST database](https://en.wikipedia.org/wiki/MNIST_database) (Modified National Institute of Standards and Technology database) is a large database of handwritten digits that is commonly used as a first test for new classification algorithms. \n",
    "We follow this tradition to investigate the performance of artificial neural networks of different complexity on MNIST. However, since MNIST is too easy for accessing the full power of modern machine learning algorithms (see e.g. [this post](https://twitter.com/goodfellow_ian/status/852591106655043584)) we will extend our analysis to the recently introduced, harder [Fashion-MNIST dataset](https://github.com/zalandoresearch/fashion-mnist).\n",
    "\n",
    "\n",
    "### Prerequisites\n",
    "\n",
    "- You should have a running installation of [tensorflow](https://www.tensorflow.org/install/) and [keras](https://keras.io/). Feel free to gain inspiration from the [Keras example directory](https://github.com/keras-team/keras/tree/master/examples) for your implementations.\n",
    "- You should know the concepts \"multilayer perceptron\", \"stochastic gradient descent with minibatches\", \"convolutional neural network\", \"training and validation data\", \"overfitting\" and \"early stopping\".\n",
    "\n",
    "### What you will learn\n",
    "\n",
    "- You will learn how to define feedforward neural networks in keras and fit them to data.\n",
    "- You will be guided through a prototyping procedure for the application of deep learning to a specific domain.\n",
    "- You will get in contact with concepts discussed later in the lecture, like \"regularization\", \"batch normalization\" and \"convolutional networks\".\n",
    "- You will gain some experience on the influence of network architecture, optimizer and regularization choices on the goodness of fit.\n",
    "- You will learn to be more patient :) Some fits may take your computer quite a bit of time; run them over night (or on an external server).\n",
    "\n",
    "### Evaluation criteria\n",
    "\n",
    "The evaluation is (mostly) based on the figures you submit and your answer sentences. Provide clear and concise answers respecting the indicated maximum length (answers to the questions should be below the line that says \"Answer to question ...\").\n",
    "\n",
    "**The submitted notebook must be run by you!** We will only do random tests of your code and not re-run the full notebook. There will be fraud detection sessions at the end of the semester.\n",
    "\n",
    "### Your names\n",
    "\n",
    "**Before you start**: please enter your full name(s) in the field below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-09T09:08:24.514461Z",
     "start_time": "2018-03-09T09:08:24.506410Z"
    }
   },
   "outputs": [],
   "source": [
    "student1 = \"Nihal Ezgi Yücetürk\"\n",
    "student2 = \"Atakan Büyükoğlu\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-22T21:52:59.697375Z",
     "start_time": "2018-02-22T21:52:59.689443Z"
    }
   },
   "source": [
    "## Some helper functions\n",
    "\n",
    "For your convenience we provide here some functions to preprocess the data and plot the results later. Simply run the following cells with `Shift-Enter`.\n",
    "\n",
    "### Dependencies and constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-23T14:27:09.352019Z",
     "start_time": "2018-02-23T14:27:08.476310Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.io\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, MaxPooling2D, Dropout, Flatten, BatchNormalization\n",
    "from keras.optimizers import SGD, Adam\n",
    "from keras.regularizers import l1, l2\n",
    "from keras.initializers import RandomNormal\n",
    "from keras.callbacks import Callback"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-23T15:11:52.252208Z",
     "start_time": "2018-02-23T15:11:52.121360Z"
    }
   },
   "outputs": [],
   "source": [
    "def plot_some_samples(x, y = [], yhat = [], select_from = [], \n",
    "                      ncols = 6, nrows = 4, xdim = 28, ydim = 28,\n",
    "                      label_mapping = range(10)):\n",
    "    \"\"\"plot some input vectors as grayscale images (optionally together with their assigned or predicted labels).\n",
    "    \n",
    "    x is an NxD - dimensional array, where D is the length of an input vector and N is the number of samples.\n",
    "    Out of the N samples, ncols x nrows indices are randomly selected from the list select_from (if it is empty, select_from becomes range(N)).\n",
    "    \n",
    "    Keyword arguments:\n",
    "    y             -- corresponding labels to plot in green below each image.\n",
    "    yhat          -- corresponding predicted labels to plot in red below each image.\n",
    "    select_from   -- list of indices from which to select the images.\n",
    "    ncols, nrows  -- number of columns and rows to plot.\n",
    "    xdim, ydim    -- number of pixels of the images in x- and y-direction.\n",
    "    label_mapping -- map labels to digits.\n",
    "    \n",
    "    \"\"\"\n",
    "    fig, ax = plt.subplots(nrows, ncols)\n",
    "    if len(select_from) == 0:\n",
    "        select_from = range(x.shape[0])\n",
    "    indices = np.random.choice(select_from, size = min(ncols * nrows, len(select_from)), replace = False)\n",
    "    for i, ind in enumerate(indices):\n",
    "        thisax = ax[i//ncols,i%ncols]\n",
    "        thisax.matshow(x[ind].reshape(xdim, ydim), cmap='gray')\n",
    "        thisax.set_axis_off()\n",
    "        if len(y) != 0:\n",
    "            j = y[ind] if type(y[ind]) != np.ndarray else y[ind].argmax()\n",
    "            thisax.text(0, 0, (label_mapping[j])%10, color='green', #deleted +1 after label_mapping[j]\n",
    "                                                       verticalalignment='top',\n",
    "                                                       transform=thisax.transAxes)\n",
    "        if len(yhat) != 0:\n",
    "            k = yhat[ind] if type(yhat[ind]) != np.ndarray else yhat[ind].argmax()\n",
    "            thisax.text(1, 0, (label_mapping[k])%10, color='red',\n",
    "                                             verticalalignment='top',\n",
    "                                             horizontalalignment='right',\n",
    "                                             transform=thisax.transAxes)\n",
    "    return fig\n",
    "\n",
    "def prepare_standardplot(title, xlabel):\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2)\n",
    "    fig.suptitle(title)\n",
    "    ax1.set_ylabel('categorical cross entropy')\n",
    "    ax1.set_xlabel(xlabel)\n",
    "    ax1.set_yscale('log')\n",
    "    ax2.set_ylabel('accuracy [% correct]')\n",
    "    ax2.set_xlabel(xlabel)\n",
    "    return fig, ax1, ax2\n",
    "\n",
    "def finalize_standardplot(fig, ax1, ax2):\n",
    "    ax1handles, ax1labels = ax1.get_legend_handles_labels()\n",
    "    if len(ax1labels) > 0:\n",
    "        ax1.legend(ax1handles, ax1labels)\n",
    "    ax2handles, ax2labels = ax2.get_legend_handles_labels()\n",
    "    if len(ax2labels) > 0:\n",
    "        ax2.legend(ax2handles, ax2labels)\n",
    "    fig.tight_layout()\n",
    "    plt.subplots_adjust(top=0.9)\n",
    "\n",
    "def plot_history(history, title):\n",
    "    fig, ax1, ax2 = prepare_standardplot(title, 'epoch')\n",
    "    ax1.plot(history.history['loss'], label = \"training\")\n",
    "    ax1.plot(history.history['val_loss'], label = \"validation\")\n",
    "    ax2.plot(history.history['acc'], label = \"training\")\n",
    "    ax2.plot(history.history['val_acc'], label = \"validation\")\n",
    "    finalize_standardplot(fig, ax1, ax2)\n",
    "    return fig\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1: Data import and visualization (4 points)\n",
    "\n",
    "### Description\n",
    "\n",
    "### Loading the data\n",
    "\n",
    "The datasets we use in this project (MNIST, Fashion-MNIST) consists of grayscale images with 28x28 pixels. Keras comes with a convenient in-built [data importer](https://keras.io/datasets/) for common datasets.\n",
    "\n",
    "1. As a warm-up exercise, use this importer to (down-)load the MNIST and Fashion-MNIST dataset. Assign useful variables to test & train images and labels for both datasets respectively. (2 pts)\n",
    "2. Use the corresponding plotting function defined above to plot some samples of the two datasets. What do the green digits at the bottom left of each image indicate? (1 sentence max.) (2 pts)\n",
    "\n",
    "The low resolution (and grayscale) of the images certainly misses some information that could be helpful for classifying the images. However, since the data has lower dimensionality due to the low resolution, the fitting procedures converge faster. This is an advantage in situations like here (or generally when prototyping), were we want to try many different things without having to wait too long for computations to finish.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-23T14:27:44.442862Z",
     "start_time": "2018-02-23T14:27:09.505547Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 24 Axes>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 24 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from keras.datasets import mnist, fashion_mnist\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "(x_fashion_train, y_fashion_train), (x_fashion_test, y_fashion_test) = fashion_mnist.load_data()\n",
    "\n",
    "plot_some_samples(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer to question 2:\n",
    "Numbers in green indicate the true image labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Data pre-processing**: To prepare for fitting we transform the labels to one hot coding, i.e. for 5 classes, label 2 becomes the vector [0, 0, 1, 0, 0] (python uses 0-indexing). Furthermore we reshape (flatten) the input images to input vectors and rescale the data into the range [0,1]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = keras.utils.to_categorical(y_train)\n",
    "y_test = keras.utils.to_categorical(y_test)\n",
    "\n",
    "y_fashion_train = keras.utils.to_categorical(y_fashion_train)\n",
    "y_fashion_test = keras.utils.to_categorical(y_fashion_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.reshape(x_train.shape[0], x_train.shape[1]*x_train.shape[2])/np.max(x_train)\n",
    "x_test = x_test.reshape(x_test.shape[0], x_test.shape[1]*x_test.shape[2])/np.max(x_test)\n",
    "\n",
    "x_fashion_train = x_fashion_train.reshape(x_fashion_train.shape[0], x_fashion_train.shape[1]*x_fashion_train.shape[2])/np.max(x_fashion_train)\n",
    "x_fashion_test = x_fashion_test.reshape(x_fashion_test.shape[0], x_fashion_test.shape[1]*x_fashion_test.shape[2])/np.max(x_fashion_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2: No hidden layer (10 points)\n",
    "\n",
    "### Description\n",
    "\n",
    "Define and fit a model without a hidden layer (since we will use multi-layer models later in this project, you can define a general constructor function for models with an arbitrary number of hidden layers already at this point). (1 pt for each step)\n",
    "\n",
    "1. Use the softmax activation for the output layer.\n",
    "2. Use the categorical_crossentropy loss.\n",
    "3. Add the accuracy metric to the metrics.\n",
    "4. Choose stochastic gradient descent for the optimizer.\n",
    "5. Choose a minibatch size of 128.\n",
    "6. Fit for as many epochs as needed to see no further decrease in the validation loss.\n",
    "7. Plot the output of the fitting procedure (a history object) using the function plot_history defined above.\n",
    "8. Determine the indices of all test images that are misclassified by the fitted model and plot some of them using the function \n",
    "   `plot_some_samples(x_test, y_test, yhat_test, error_indices)`. Explain the green and red digits at the bottom of each image.\n",
    "9. Repeat the above steps for fitting the network to the Fashion-MNIST dataset.\n",
    "\n",
    "\n",
    "Hints:\n",
    "* Read the keras docs, in particular [Getting started with the Keras Sequential model](https://keras.io/getting-started/sequential-model-guide/).\n",
    "* Have a look at the keras [examples](https://github.com/keras-team/keras/tree/master/examples), e.g. [mnist_mlp](https://github.com/keras-team/keras/blob/master/examples/mnist_mlp.py)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialize model parameters\n",
    "num_classes = 10\n",
    "in_shape = x_train[0].shape\n",
    "batch_size = 128\n",
    "epochs = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define all callback classes to be used for early stopping\n",
    "# For all classes,\n",
    "# Epsilon is the threshold parameter\n",
    "# Percentage is optional, but is a percent threshold to be checked if entered, input 0.01 means 1%\n",
    "\n",
    "class stopAtValAccDecrease(Callback):\n",
    "# If validation accuracy drops more than epsilon in value in the next epoch training stops\n",
    "# If validation accuracy drops more than a particular percentage of the current accuracy in the next epoch training stops\n",
    "    def __init__(self, eps = 0.1, perc = None):\n",
    "        self.eps = eps\n",
    "        self.prev_acc = 0\n",
    "        self.perc = perc\n",
    "    \n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        #loss = logs.get('loss')\n",
    "        acc = logs.get('val_acc')\n",
    "        if ( self.prev_acc - acc) >= self.eps or ( self.perc is not None and self.prev_acc / acc - 1 >= self.perc ):\n",
    "            self.model.stop_training = True\n",
    "            self.prev_acc = 0\n",
    "            print('Stopped due to High Validation Accuracy Decrease')\n",
    "        else:\n",
    "            self.prev_acc = acc\n",
    "            \n",
    "\n",
    "class stopAtValLossIncrease(Callback):\n",
    "# If validation loss increases more than epsilon in value in the next epoch training stops\n",
    "\n",
    "    def __init__(self, eps = 0.1, perc = None):\n",
    "        self.eps = eps\n",
    "        self.prev_loss = np.Infinity\n",
    "        self.perc = perc\n",
    "    \n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        #loss = logs.get('loss')\n",
    "        loss = logs.get('val_loss')\n",
    "        if (loss - self.prev_loss) >= self.eps or ( self.perc is not None and loss / self.prev_loss - 1 >= self.perc ):\n",
    "            self.model.stop_training = True\n",
    "            self.prev_loss = np.Infinity\n",
    "            print('Stopped due to High Validation Loss Increase')\n",
    "        else:\n",
    "            self.prev_loss = loss\n",
    "\n",
    "                \n",
    "class stopAtTraValLossDiff(Callback):\n",
    "# If difference between training loss and validation loss is more than epsilon in value training stops\n",
    "\n",
    "    def __init__(self, eps = 0.1, perc = None):\n",
    "        self.eps = eps\n",
    "        self.perc = perc\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        val_loss = logs.get('val_loss')\n",
    "        tra_loss = logs.get('loss')\n",
    "        if (val_loss - tra_loss) >= self.eps or ( self.perc is not None and val_loss / tra_loss - 1 >= self.perc ):\n",
    "            self.model.stop_training = True\n",
    "            print('Stopped due to High Training-Validation Loss Difference')\n",
    "                \n",
    "                \n",
    "class stopAtTraValAccDiff(Callback):\n",
    "# If difference between training accuracy and validation accuracy is more than epsilon in value training stops\n",
    "\n",
    "    def __init__(self, eps = 0.1, perc = None):\n",
    "        self.eps = eps\n",
    "        self.perc = perc\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        val_acc = logs.get('val_acc')\n",
    "        tra_acc = logs.get('acc')\n",
    "        if (tra_acc - val_acc) >= self.eps or ( self.perc is not None and tra_acc / val_acc - 1 >= self.perc ):\n",
    "            self.model.stop_training = True\n",
    "            print('Stopped due to High Training-Validation Accuracy Difference')\n",
    "\n",
    "                \n",
    "class stopAtStableLoss(Callback):\n",
    "# If training drops less than epsilon in value in the next epoch training stops\n",
    "    def __init__(self, eps = 0.001, perc = None):\n",
    "        self.eps = eps\n",
    "        self.prev_loss = np.Infinity\n",
    "        self.perc = perc\n",
    "    \n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        #loss = logs.get('loss')\n",
    "        loss = logs.get('loss')\n",
    "        if (self.prev_loss - loss) <= self.eps or ( self.perc is not None and 1 - loss / self.prev_loss <= self.perc ):\n",
    "            self.model.stop_training = True\n",
    "            self.prev_loss = np.Infinity\n",
    "            print('Stopped due to Too Stable Loss')\n",
    "        else:\n",
    "            self.prev_loss = loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the callback instances\n",
    "callbacks = [stopAtValAccDecrease(eps = 0.1),\n",
    "             stopAtValLossIncrease(eps = 0.1),\n",
    "             stopAtTraValLossDiff(eps = 0.1),\n",
    "             stopAtTraValAccDiff(eps = 0.1),\n",
    "             stopAtStableLoss(eps = 0, perc = 0.01)\n",
    "            ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(num_classes, activation='softmax', input_shape=in_shape))\n",
    "#model.add(Dense(num_classes, activation='softmax'))\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='SGD',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(x_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    callbacks = callbacks, validation_split = 0.15 )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_history(history, \"Here is the title\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def misclassed_incides():\n",
    "    pred_y = model.predict_classes(x_test)\n",
    "    y_orig = np.argmax(y_test, axis=1)\n",
    "    if len(pred_y)!= len(y_orig):\n",
    "        raise ValueError('LEnght mismatch')\n",
    "    err = np.nonzero(pred_y - y_orig)[0]\n",
    "    plot_some_samples(x_test, y_orig, pred_y, select_from=err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "misclassed_incides()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer to question 10: Green ones are the true lables of the data points whereas the red ones are what our model predicted for the corresponding data point"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3: One hidden layer, different optizimizers & overfitting (10 points)\n",
    "\n",
    "### Description\n",
    "\n",
    "Train a network with one hidden layer and compare different optimizers.\n",
    "\n",
    "1. Use one hidden layer with 128 units and the 'relu' activation. Use the [summary method](https://keras.io/models/about-keras-models/) to display your model in a compact way. (1 pt)\n",
    "2. Fit the model for 50 epochs with different learning rates of stochastic gradient descent (SGD). (1pt)\n",
    "3. Replace the stochastic gradient descent optimizer with the [Adam optimizer](https://keras.io/optimizers/#adam). (1pt)\n",
    "4. Plot the learning curves of SGD with a reasonable learning rate (i.e. in the range [0.01,0.1]) together with the learning curves of Adam in the same figure. Take care of a reasonable labeling of the curves in the plot. (2pts)\n",
    "5. Answer the questions below. (4pts)\n",
    "6. Run the network (using the Adam optimizer) on the Fashion-MNIST dataset and plot the learning curves using the plot_history function defined above. (1pt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 1\n",
    "def model_Q3():\n",
    "    # Create the model\n",
    "    model = Sequential()\n",
    "\n",
    "    # Add the layers\n",
    "    model.add(Dense(128, activation='relu', input_shape=in_shape))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    return model\n",
    "\n",
    "model_Q3().summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_list = np.arange(0.01,0.11,0.01)\n",
    "batch_size = 128\n",
    "epochs = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 2\n",
    "sgd_acc_list = []\n",
    "model = model_Q3()\n",
    "for lr_ in lr_list:\n",
    "    # Add the learning rate parameter to the model\n",
    "    sgd = SGD(lr=lr_)\n",
    "    #TODO: This does not refresh the model weights\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=sgd,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "# Fit the model\n",
    "    history_sgd = model.fit(x_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    callbacks = callbacks, validation_data = (x_test, y_test) )\n",
    "    \n",
    "    sgd_acc_list.append(history_sgd.history['acc'][-1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_chosen = lr_list[np.argmax(sgd_acc_list)]\n",
    "lr_chosen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd = SGD(lr=lr_chosen)\n",
    "model = model_Q3()\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=sgd,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "# Fit the model\n",
    "history_sgd = model.fit(x_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    callbacks = None, validation_data = (x_test, y_test) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adm = Adam(lr=lr_chosen / 10)\n",
    "model = model_Q3()\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=adm,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "# Fit the model\n",
    "history_adam = model.fit(x_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    callbacks = None, validation_data = (x_test, y_test) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-23T15:42:45.497806Z",
     "start_time": "2018-02-23T15:42:44.961166Z"
    }
   },
   "outputs": [],
   "source": [
    "# This plotting routine might help you ...\n",
    "def comparison_plot(history_sgd, history_adam, label1, label2, title):\n",
    "    fig, ax1, ax2 = prepare_standardplot(title, \"epochs\")\n",
    "    \n",
    "    ax1.plot(history_sgd.history['loss'], label=label1 + ' training' )\n",
    "    ax1.plot(history_sgd.history['val_loss'], label=label1 + ' validation')\n",
    "    ax1.plot(history_adam.history['loss'], label=label2 + ' training')\n",
    "    ax1.plot(history_adam.history['val_loss'], label=label2 + ' validation')\n",
    "    ax1.legend(loc='lower left')\n",
    "    \n",
    "    ax2.plot(history_sgd.history['acc'], label=label1 + ' training')\n",
    "    ax2.plot(history_sgd.history['val_acc'], label=label1 + ' validation')\n",
    "    ax2.plot(history_adam.history['acc'], label=label2 + ' training')\n",
    "    ax2.plot(history_adam.history['val_acc'], label=label2 + ' validation')\n",
    "    ax2.legend(loc='lower left')\n",
    "    \n",
    "    finalize_standardplot(fig, ax1, ax2)\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison_plot(history_sgd, history_adam, 'SGD_LR'+str(lr_chosen), 'Adam_LR'+str(lr_chosen), 'Learning Curves SGD vs Adam' );"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question**: What happens if the learning rate of SGD is A) very large B) very small? Please answer A) and B) with one full sentence each (double click this markdown cell to edit).\n",
    "\n",
    "**Answer**:\n",
    "\n",
    "A)It overshoots the minimum of the error function and loss starts to increase after some epochs.\n",
    "\n",
    "B)It takes very long time (too much epochs) for SGD to converge the minimum of the error curve.\n",
    "\n",
    "**Question**: At which epoch (approximately) does the Adam optimizer start to overfit (on MNIST)? Please answer with one full sentence.\n",
    "\n",
    "**Answer**: It starts overfitting apporoximately in 15th epoch; after 20 more reliably.\n",
    "\n",
    "**Question**: Explain the qualitative difference between the loss curves and the accuracy curves with respect to signs of overfitting. Please answer with at most 3 full sentences.\n",
    "\n",
    "**Answer**: For loss curves, training loss approaches to zero when number of epochs increases so does validation loss but validation loss starts to increase again when overfitting begins. For accuracy curves, both increases until overfitting begins. Training accuracy approaches to 100 while validation accuracy stays stable or decreases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 4: Model performance as a function of number of hidden neurons (8 points)\n",
    "\n",
    "### Description\n",
    "\n",
    "Investigate how the best validation loss and accuracy depends on the number of hidden neurons in a single layer.\n",
    "\n",
    "1. Fit a reasonable number of models (e.g. 5) with different hidden layer sizes (between 10 and 1000 hidden neurons) to the MNIST dataset. You may use the Adam optimizer and a meaningful number of epochs (overfitting!). (3 pts)\n",
    "2. Plot the best validation loss and accuracy versus the number of hidden neurons. Is the observed trend in accordance with the [general approximation theorem](https://en.wikipedia.org/wiki/Universal_approximation_theorem)? If not, what might be practical reasons for the deviation? (2 sentences max.) (3 pts)\n",
    "3. Repeat steps 1. & 2. for the Fashion-MNIST dataset. (2 pts)\n",
    "\n",
    "In this exercise we fit each model only for one initialization and random seed. In practice one would collect some statistics (e.g. 25-, 50-, 75-percentiles) for each layer size by fitting each model several times with different initializations and the random seeds. You may also want to do this here. It is a good exercise, but not mandatory as it takes quite a bit of computation time.\n",
    "\n",
    "### Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-23T14:58:15.181352Z",
     "start_time": "2018-02-23T14:31:52.623267Z"
    }
   },
   "outputs": [],
   "source": [
    "# Part 1\n",
    "\n",
    "#The number of neurons in the hidden layers\n",
    "neuron_counts = [10, 100, 250, 500, 1000]\n",
    "adm = Adam(lr= 0.001)\n",
    "batch_size = 128\n",
    "epochs = 15\n",
    "\n",
    "\n",
    "\n",
    "#Keep history for the next part\n",
    "histories = []\n",
    "\n",
    "# Fit the model for different hidden neuron counts\n",
    "for num_hidden in neuron_counts:\n",
    "    \n",
    "    # Create the model\n",
    "    model = Sequential()\n",
    "\n",
    "    # Add the layers\n",
    "    model.add(Dense(num_hidden, activation='relu', input_shape=in_shape))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "    # Add the optimization parameters to the model\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer=adm,\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    # Model summary\n",
    "    model.summary()\n",
    "    # Fit the model\n",
    "    \n",
    "    histories.append( model.fit(x_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    callbacks = callbacks, validation_data = (x_test, y_test) )\n",
    "                    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 2\n",
    "\n",
    "# Variables to hold validation loss and accuracy maximums\n",
    "val_loss_max = []\n",
    "val_acc_max = []\n",
    "\n",
    "for history in histories:\n",
    "    val_loss_max.append(min(history.history['val_loss']))\n",
    "    val_acc_max.append(max(history.history['val_acc']))\n",
    "    \n",
    "# Plot the results\n",
    "fig, ax1, ax2 = prepare_standardplot('Validation Performance', 'Number of Hidden Neurons')\n",
    "ax1.plot(neuron_counts, val_loss_max, label = \"Validation Loss\")\n",
    "ax2.plot(neuron_counts, val_acc_max, label = \"Validation Accuracy\")\n",
    "#ax1.set_xscale('log')\n",
    "#ax2.set_xscale('log')\n",
    "finalize_standardplot(fig, ax1, ax2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer to question 2:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 5: Going deeper: tricks and regularization (8 points)\n",
    "\n",
    "### Description\n",
    "\n",
    "Adding hidden layers to a deep network does not necessarily lead to a straight-forward improvement of performance. Overfitting can be counteracted with regularization and dropout. Batch normalization is supposed to mainly speed up convergence. Since the MNIST dataset is almost perfectly solved already by a one-hidden-layer network we use the Fashion-MNIST dataset in this exercise.\n",
    "\n",
    "1. Add one or two hidden layers with 50 hidden neurons (each) and train the network for a sufficiently long time (at least 100 epochs). Since deep models are very expressive you will most probably encounter overfitting. Try to improve the best validation scores of the model (even if it is only a minor improvement) by experimenting with batch_normalization layers, dropout layers and l1- and l2-regularization on weights (kernels) and biases. (4 pts)\n",
    "2. After you have found good settings, plot the learning curves for both models, naive (=no tricks/regularization) and tuned (=tricks + regularized), preferably together in a comparison plot. Discuss your results; refer to the model performance with only 1 hidden layer. (2 sentences max.) (2pts)\n",
    "3. Fit your best performing (probably regularized deep) model also to MNIST for having a reference for the next exercise. Plot the resulting learning curves. (2 pts)\n",
    "\n",
    "### Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-23T16:26:50.480763Z",
     "start_time": "2018-02-23T16:06:32.938435Z"
    }
   },
   "outputs": [],
   "source": [
    "adm = Adam(lr = 0.001)\n",
    "num_classes = 10\n",
    "in_shape = x_fashion_train[0].shape\n",
    "batch_size = 128\n",
    "epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_out = [False, True]\n",
    "batch_norm = [False, True]\n",
    "l2_reg= [False, True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "histories = []\n",
    "for dr in drop_out:\n",
    "    for bn in batch_norm:\n",
    "        for l_2 in l2_reg:\n",
    "                # Create the model\n",
    "                model = Sequential()\n",
    "                if l_2:\n",
    "                    if bn:\n",
    "                        model.add(Dense(50, activation='relu', input_shape=in_shape, bias_initializer = RandomNormal(),\n",
    "                                   kernel_regularizer = l2()))\n",
    "                        model.add(BatchNormalization())\n",
    "                        model.add(Dense(50, activation='relu', bias_initializer = RandomNormal(), \n",
    "                                    kernel_regularizer = l2()))\n",
    "                        model.add(BatchNormalization())\n",
    "                    else :\n",
    "                        model.add(Dense(50, activation='relu', input_shape=in_shape, bias_initializer = RandomNormal(),\n",
    "                                   kernel_regularizer = l2()))\n",
    "                        model.add(Dense(50, activation='relu', bias_initializer = RandomNormal(), \n",
    "                                    kernel_regularizer = l2()))\n",
    "                else:\n",
    "                    if bn:\n",
    "                        model.add(Dense(50, activation='relu', input_shape=in_shape, bias_initializer = RandomNormal(),\n",
    "                                   kernel_regularizer = l1()))\n",
    "                        model.add(BatchNormalization())\n",
    "                        model.add(Dense(50, activation='relu', bias_initializer = RandomNormal(),\n",
    "                                   kernel_regularizer = l1()))\n",
    "                        model.add(BatchNormalization())\n",
    "                    else:\n",
    "                        model.add(Dense(50, activation='relu', input_shape=in_shape, bias_initializer = RandomNormal(),\n",
    "                                   kernel_regularizer = l1()))\n",
    "                        model.add(Dense(50, activation='relu', bias_initializer = RandomNormal(),\n",
    "                                   kernel_regularizer = l1()))            \n",
    "                \n",
    "                if dr:\n",
    "                    model.add(Dropout(0.5))\n",
    "                \n",
    "                model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "                # Add the optimization parameters to the model\n",
    "                model.compile(loss='categorical_crossentropy',\n",
    "                      optimizer=adm,\n",
    "                      metrics=['accuracy'])\n",
    "                \n",
    "                hist = model.fit(x_fashion_train,y_fashion_train,\n",
    "                          batch_size=batch_size,\n",
    "                          epochs=epochs,\n",
    "                        verbose=1,\n",
    "                        callbacks = callbacks, validation_data = (x_fashion_test, y_fashion_test) )\n",
    "                    \n",
    "                histories.append(hist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer to question 2 (comments):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 6: Convolutional neural networks (CNNs) (10 points)\n",
    "\n",
    "### Description\n",
    "\n",
    "Convolutional neural networks have an inductive bias that is well adapted to image classification.\n",
    "\n",
    "1. Design a convolutional neural network, play with different architectures and parameters. Hint: You may get valuable inspiration from the keras [examples](https://github.com/keras-team/keras/tree/master/examples). (4 pts)\n",
    "2. Plot the learning curves of the convolutional neural network for MNIST and Fashion-MNIST. (4 pts)\n",
    "3. How does the CNN performance compare to the so far best performing (deep) neural network model for the two data sets? (2 sentences max.) (2 pts)\n",
    "\n",
    "### Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-23T16:05:21.840299Z",
     "start_time": "2018-02-23T15:51:11.993053Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer to question 3:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 7: Sigmoidal activation function and batch-normalization (6 points)\n",
    "\n",
    "### Description:\n",
    "\n",
    "In the original publication of batch normalization [Ioffe and Szegedy, 2014](https://arxiv.org/pdf/1502.03167.pdf), the authors mention a particularly beneficial effect of their method on networks with sigmoidal activation functions. This is because such networks usually suffer from saturating activations/vanishing gradients. Here we want to reproduce this behaviour (Chose either MNIST or Fashion-MNIST for this exercise).\n",
    "\n",
    "1. Implement the same convolutional network as in the previous exercise, but using the sigmoid activation function instead of the standard choice ReLU. Train the network for a reasonable amount of time. What do you observe? (1 sentence max.) (3 pts)\n",
    "2. Add batch-normalization layers to all convolutional and fully-connected layers (i.e. before each layer with learnable parameters). How does the performance change? Can the network reach the ReLU-CNN performance of the previous exercise? (1 sentence max.) (3 pts)\n",
    "3. **BONUS (optional, not graded**): Investigate our initial guess that saturating activity/vanishing gradients might be the cause of this behaviour. For that, create histograms of the hidden activitions for different hidden layers for the sigmoid-CNN and the sigmoid-CNN with batch-normalization (counting over both, samples and neurons per layer). You may only chose layers with learnable parameters. What do you observe?\n",
    "Hint: You can use the [keract](https://github.com/philipperemy/keract) package to access neural activation values for all layers of your network model.\n",
    "\n",
    "\n",
    "\n",
    "### Solution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer to question 1:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer to question 2:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
